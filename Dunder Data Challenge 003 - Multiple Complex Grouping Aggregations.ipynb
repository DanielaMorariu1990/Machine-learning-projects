{"cells":[{"metadata":{},"cell_type":"markdown","source":["# Multiple Custom Grouping Aggregations\n","\n","This challenge is going to be fairly difficult, but should answer a question that many pandas users face - What is the best way to do a grouping operation that does many custom aggregations? In this context, a 'custom aggregation' is defined as one that is not directly available to use from pandas and one that you must write a custom function for. \n","\n","In Pandas Challenge 1, a single aggregation, which required a custom grouping function, was the desired result. In this challenge, you'll need to make several aggregations when grouping. There are a few different solutions to this problem, but depending on how you arrive at your solution, there could arise enormous performance differences. I am looking for a compact, readable solution with very good performance.\n","\n","### Sales Data\n","\n","In this challenge, you will be working with some mock sales data found in the sales.csv file. It contains 200,000 rows and 9 columns."]},{"metadata":{"trusted":false},"cell_type":"code","source":["import pandas as pd"],"execution_count":2,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":["df = pd.read_csv('sales.csv', parse_dates=['date'])\n","df.head()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":"   customer_id       date     country region delivery_type    cost_type  \\\n0        13763 2019-03-25    Portugal      F          slow       expert   \n1        13673 2019-12-06   Singapore      I          slow  experienced   \n2        10287 2018-09-04       India      I          slow       novice   \n3        14298 2018-06-21     Morocco      F       fastest       expert   \n4        11523 2019-01-05  Luxembourg      A          fast       expert   \n\n   duration  revenue  cost  \n0        60      553   295  \n1        60      895   262  \n2        60      857   260  \n3       120      741   238  \n4       120      942   263  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>date</th>\n      <th>country</th>\n      <th>region</th>\n      <th>delivery_type</th>\n      <th>cost_type</th>\n      <th>duration</th>\n      <th>revenue</th>\n      <th>cost</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13763</td>\n      <td>2019-03-25</td>\n      <td>Portugal</td>\n      <td>F</td>\n      <td>slow</td>\n      <td>expert</td>\n      <td>60</td>\n      <td>553</td>\n      <td>295</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13673</td>\n      <td>2019-12-06</td>\n      <td>Singapore</td>\n      <td>I</td>\n      <td>slow</td>\n      <td>experienced</td>\n      <td>60</td>\n      <td>895</td>\n      <td>262</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10287</td>\n      <td>2018-09-04</td>\n      <td>India</td>\n      <td>I</td>\n      <td>slow</td>\n      <td>novice</td>\n      <td>60</td>\n      <td>857</td>\n      <td>260</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14298</td>\n      <td>2018-06-21</td>\n      <td>Morocco</td>\n      <td>F</td>\n      <td>fastest</td>\n      <td>expert</td>\n      <td>120</td>\n      <td>741</td>\n      <td>238</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11523</td>\n      <td>2019-01-05</td>\n      <td>Luxembourg</td>\n      <td>A</td>\n      <td>fast</td>\n      <td>expert</td>\n      <td>120</td>\n      <td>942</td>\n      <td>263</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":3}]},{"metadata":{"trusted":false},"cell_type":"code","source":["df.shape"],"execution_count":3,"outputs":[{"data":{"text/plain":"(200000, 9)"},"execution_count":3,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":["### Challenge\n","\n","There are many aggregations that you will need to return and it will take some time to understand what they are and how to return them. The following definitions for two time periods will be used throughout the aggregations.\n","\n","Period **2019H1** is defined as the time period beginning January 1, 2019 and ending June 30, 2019.\n","Period **2018H1** is defined as the time period beginning January 1, 2018 and ending June 30, 2018.\n","\n","### Aggregations\n","Now, I will list all the aggregations that are expected to be returned. Each bullet point represents a single column. Use the first word after the bullet point as the new column name.\n","\n","For every country and region, return the following:\n","* recency: Number of days between today's date (9/9/2019) and the maximum value of the 'date' column \n","* fast_and_fastest: Number of unique customer_id in period 2019H1 with delivery_type either 'fast' or 'fastest'\n","* rev_2019: Total revenue for the period 2019H1\n","* rev_2018: Total revenue for the period 2018H1\n","* cost_2019: Total cost for period 2019H1\n","* cost_2019_exp: Total cost for period 2019H1 with cost_type 'expert'\n","* other_cost: Difference between cost_2019 and cost_2019_exp\n","* rev_per_60: Total of revenue when duration equals 60 in period 2019H1 divided by number of unique customer_id when duration equals 60 in period 2019H1 \n","* profit_margin: Take the difference of rev_2019 and cost_2019_exp then divide by rev_2019. Return as percentage\n","* cost_exp_per_60: Total of cost when duration is 60 and cost_type is 'expert' in period 2019H1 divided by the number of unique customer_id when duration equals 60 and cost_type is 'expert' in period 2019H1 \n","* growth: Find the percentage growth from revenue in period 2019H1 compared to the revenue in period 2018H1"]},{"metadata":{"trusted":false},"cell_type":"code","source":["from datetime import datetime\n","def date_dif(df):\n","    d1=datetime.strptime(\"2019-09-09\",\"%Y-%m-%d\")\n","    d2=max(df[\"date\"])\n","    return (d2-d1).days\n","\n","df[[\"region\",\"country\",\"date\"]].groupby([\"region\", \"country\"]).apply(date_dif)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":"region  country             \nA       Argentina               86\n        Australia               88\n        Austria                 88\n        Belgium                 88\n        Brazil                  88\n                                ..\nJ       Ukraine                 88\n        United Arab Emirates    86\n        United Kingdom          88\n        United States           88\n        Vietnam                 86\nLength: 520, dtype: int64"},"metadata":{},"execution_count":13}]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[],"source":["start_date=datetime.strptime(\"2019-01-01\",\"%Y-%m-%d\")\n","end_date= datetime.strptime(\"2019-06-06\",\"%Y-%m-%d\")\n","mask=(df[\"date\"]<=end_date) & (df[\"date\"]>=start_date)\n","new_df=df[mask][[\"customer_id\",\"delivery_type\", \"country\",\"region\"]]\n","new_df\n","new_df[\"fast_and_fastest\"]=new_df[df[\"delivery_type\"].isin([\"fast\",\"fastest\"])].groupby([ \"region\",\"country\",\"delivery_type\"]).transform(\"count\")\n"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"                  revenue\ncountry   region         \nArgentina A        123843\n          B        124205\n          C        105129\n          D        112833\n          E        131384\n...                   ...\nVietnam   F        125282\n          G        129496\n          H        122348\n          I        115814\n          J        122519\n\n[520 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>revenue</th>\n    </tr>\n    <tr>\n      <th>country</th>\n      <th>region</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">Argentina</th>\n      <th>A</th>\n      <td>123843</td>\n    </tr>\n    <tr>\n      <th>B</th>\n      <td>124205</td>\n    </tr>\n    <tr>\n      <th>C</th>\n      <td>105129</td>\n    </tr>\n    <tr>\n      <th>D</th>\n      <td>112833</td>\n    </tr>\n    <tr>\n      <th>E</th>\n      <td>131384</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">Vietnam</th>\n      <th>F</th>\n      <td>125282</td>\n    </tr>\n    <tr>\n      <th>G</th>\n      <td>129496</td>\n    </tr>\n    <tr>\n      <th>H</th>\n      <td>122348</td>\n    </tr>\n    <tr>\n      <th>I</th>\n      <td>115814</td>\n    </tr>\n    <tr>\n      <th>J</th>\n      <td>122519</td>\n    </tr>\n  </tbody>\n</table>\n<p>520 rows × 1 columns</p>\n</div>"},"metadata":{},"execution_count":61}],"source":["df[mask][[\"country\",\"region\",\"revenue\"]].groupby([\"country\",\"region\"]).sum()"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"                   cost\ncountry   region       \nArgentina A       40891\n          B       41253\n          C       34648\n          D       37651\n          E       44679\n...                 ...\nVietnam   F       40848\n          G       42525\n          H       41262\n          I       39844\n          J       40402\n\n[520 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>cost</th>\n    </tr>\n    <tr>\n      <th>country</th>\n      <th>region</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">Argentina</th>\n      <th>A</th>\n      <td>40891</td>\n    </tr>\n    <tr>\n      <th>B</th>\n      <td>41253</td>\n    </tr>\n    <tr>\n      <th>C</th>\n      <td>34648</td>\n    </tr>\n    <tr>\n      <th>D</th>\n      <td>37651</td>\n    </tr>\n    <tr>\n      <th>E</th>\n      <td>44679</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">Vietnam</th>\n      <th>F</th>\n      <td>40848</td>\n    </tr>\n    <tr>\n      <th>G</th>\n      <td>42525</td>\n    </tr>\n    <tr>\n      <th>H</th>\n      <td>41262</td>\n    </tr>\n    <tr>\n      <th>I</th>\n      <td>39844</td>\n    </tr>\n    <tr>\n      <th>J</th>\n      <td>40402</td>\n    </tr>\n  </tbody>\n</table>\n<p>520 rows × 1 columns</p>\n</div>"},"metadata":{},"execution_count":66}],"source":["df[mask][[\"cost\",\"country\",\"region\"]].groupby([\"country\",\"region\"]).sum()"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"                             Revenue 2019  Revenue 2018  Cost 2019  \\\nregion country                                                       \nA      Argentina                  123.843        82.912     40.891   \n       Australia                  118.855        95.464     39.466   \n       Austria                    105.700        92.148     34.543   \n       Belgium                    113.085        81.593     39.272   \n       Brazil                     137.316        83.937     45.951   \n...                                   ...           ...        ...   \nJ      Ukraine                    107.139        93.077     35.688   \n       United Arab Emirates       100.303        82.973     34.991   \n       United Kingdom             120.896        76.645     40.075   \n       United States              138.124        88.374     46.487   \n       Vietnam                    122.519        90.094     40.402   \n\n                             Expert cost 2019  Other costs  Revenue per 60d  \\\nregion country                                                                \nA      Argentina                       15.593       25.298         0.769861   \n       Australia                       12.056       27.410         0.773264   \n       Austria                         12.756       21.787         0.756845   \n       Belgium                         13.359       25.913         0.726125   \n       Brazil                          20.875       25.076         0.763469   \n...                                       ...          ...              ...   \nJ      Ukraine                         11.159       24.529         0.762556   \n       United Arab Emirates            11.264       23.727         0.735373   \n       United Kingdom                  13.031       27.044         0.744635   \n       United States                   16.473       30.014         0.768615   \n       Vietnam                         15.129       25.273         0.761549   \n\n                             Profit margin  Expert cost for 60 days     Growth  \nregion country                                                                  \nA      Argentina                 66.981582                 0.251147  49.366799  \n       Australia                 66.794834                 0.261667  24.502430  \n       Austria                   67.319773                 0.250000  14.706776  \n       Belgium                   65.272140                 0.267231  38.596448  \n       Brazil                    66.536310                 0.258361  63.594124  \n...                                    ...                      ...        ...  \nJ      Ukraine                   66.690001                 0.250048  15.107921  \n       United Arab Emirates      65.114702                 0.245000  20.886312  \n       United Kingdom            66.851674                 0.248259  57.735012  \n       United States             66.344010                 0.260412  56.294838  \n       Vietnam                   67.023890                 0.248406  35.990188  \n\n[520 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Revenue 2019</th>\n      <th>Revenue 2018</th>\n      <th>Cost 2019</th>\n      <th>Expert cost 2019</th>\n      <th>Other costs</th>\n      <th>Revenue per 60d</th>\n      <th>Profit margin</th>\n      <th>Expert cost for 60 days</th>\n      <th>Growth</th>\n    </tr>\n    <tr>\n      <th>region</th>\n      <th>country</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">A</th>\n      <th>Argentina</th>\n      <td>123.843</td>\n      <td>82.912</td>\n      <td>40.891</td>\n      <td>15.593</td>\n      <td>25.298</td>\n      <td>0.769861</td>\n      <td>66.981582</td>\n      <td>0.251147</td>\n      <td>49.366799</td>\n    </tr>\n    <tr>\n      <th>Australia</th>\n      <td>118.855</td>\n      <td>95.464</td>\n      <td>39.466</td>\n      <td>12.056</td>\n      <td>27.410</td>\n      <td>0.773264</td>\n      <td>66.794834</td>\n      <td>0.261667</td>\n      <td>24.502430</td>\n    </tr>\n    <tr>\n      <th>Austria</th>\n      <td>105.700</td>\n      <td>92.148</td>\n      <td>34.543</td>\n      <td>12.756</td>\n      <td>21.787</td>\n      <td>0.756845</td>\n      <td>67.319773</td>\n      <td>0.250000</td>\n      <td>14.706776</td>\n    </tr>\n    <tr>\n      <th>Belgium</th>\n      <td>113.085</td>\n      <td>81.593</td>\n      <td>39.272</td>\n      <td>13.359</td>\n      <td>25.913</td>\n      <td>0.726125</td>\n      <td>65.272140</td>\n      <td>0.267231</td>\n      <td>38.596448</td>\n    </tr>\n    <tr>\n      <th>Brazil</th>\n      <td>137.316</td>\n      <td>83.937</td>\n      <td>45.951</td>\n      <td>20.875</td>\n      <td>25.076</td>\n      <td>0.763469</td>\n      <td>66.536310</td>\n      <td>0.258361</td>\n      <td>63.594124</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">J</th>\n      <th>Ukraine</th>\n      <td>107.139</td>\n      <td>93.077</td>\n      <td>35.688</td>\n      <td>11.159</td>\n      <td>24.529</td>\n      <td>0.762556</td>\n      <td>66.690001</td>\n      <td>0.250048</td>\n      <td>15.107921</td>\n    </tr>\n    <tr>\n      <th>United Arab Emirates</th>\n      <td>100.303</td>\n      <td>82.973</td>\n      <td>34.991</td>\n      <td>11.264</td>\n      <td>23.727</td>\n      <td>0.735373</td>\n      <td>65.114702</td>\n      <td>0.245000</td>\n      <td>20.886312</td>\n    </tr>\n    <tr>\n      <th>United Kingdom</th>\n      <td>120.896</td>\n      <td>76.645</td>\n      <td>40.075</td>\n      <td>13.031</td>\n      <td>27.044</td>\n      <td>0.744635</td>\n      <td>66.851674</td>\n      <td>0.248259</td>\n      <td>57.735012</td>\n    </tr>\n    <tr>\n      <th>United States</th>\n      <td>138.124</td>\n      <td>88.374</td>\n      <td>46.487</td>\n      <td>16.473</td>\n      <td>30.014</td>\n      <td>0.768615</td>\n      <td>66.344010</td>\n      <td>0.260412</td>\n      <td>56.294838</td>\n    </tr>\n    <tr>\n      <th>Vietnam</th>\n      <td>122.519</td>\n      <td>90.094</td>\n      <td>40.402</td>\n      <td>15.129</td>\n      <td>25.273</td>\n      <td>0.761549</td>\n      <td>67.023890</td>\n      <td>0.248406</td>\n      <td>35.990188</td>\n    </tr>\n  </tbody>\n</table>\n<p>520 rows × 9 columns</p>\n</div>"},"metadata":{},"execution_count":83}],"source":["def final_agg(df):\n","    start_date=datetime.strptime(\"2019-01-01\",\"%Y-%m-%d\")\n","    end_date= datetime.strptime(\"2019-06-06\",\"%Y-%m-%d\")\n","    H12019=df[\"date\"].between(start_date,end_date)\n","    H12018=df[\"date\"].between(\"2018-01-01\",\"2018-06-30\")\n","    duartion=df[\"duration\"].isin([\"60\"])\n","    exp=df[\"cost_type\"].isin([\"expert\"])\n","    h12019_exp_duration=H12019 & duartion & exp\n","  \n","\n","  ##calculate fields:\n","    rev_2019=df.loc[H12019,\"revenue\"].sum()/1_000\n","    rev_2018=df.loc[H12018,\"revenue\"].sum()/1_000\n","    cost_2019=df.loc[H12019,\"cost\"].sum()/1_000\n","    cost_2019_exp=df.loc[H12019,\"cost\"][df[\"cost_type\"].isin([\"expert\"])].sum()/1_000\n","    other_costs=cost_2019-cost_2019_exp\n","    rev_per_60=df.loc[H12019,\"revenue\"][df[\"duration\"].isin([\"60\"])].sum()/df.loc[H12019,\"customer_id\"][df[\"duration\"].isin([\"60\"])].nunique()/1_000\n","    profit_margin=(rev_2019 - cost_2019)/rev_2019*100\n","    growth=(rev_2019/rev_2018-1) *100\n","    cost_exp_per_60= df.loc[h12019_exp_duration,\"cost\"].sum()/df.loc[h12019_exp_duration,\"customer_id\"].nunique()/1_000\n","    d={ \"Revenue 2019\": rev_2019, \"Revenue 2018\": rev_2018, \"Cost 2019\": cost_2019,\"Expert cost 2019\": cost_2019_exp,\n","    \"Other costs\": other_costs, \"Revenue per 60d\": rev_per_60, \"Profit margin\":profit_margin,\n","    \"Expert cost for 60 days\":cost_exp_per_60, \"Growth\": growth\n","\n","    }\n","\n","    return pd.Series(d)\n","\n","df.groupby([\"region\",\"country\"]).apply(final_agg)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"metadata":{},"cell_type":"markdown","source":["# Become a pandas expert\n","\n","If you are looking to completely master the pandas library and become a trusted expert for doing data science work, check out my book [Master Data Analysis with Python][1]. It comes with over 300 exercises with detailed solutions covering the pandas library in-depth.\n","\n","[1]: https://www.dunderdata.com/master-data-analysis-with-python"]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3-final","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}